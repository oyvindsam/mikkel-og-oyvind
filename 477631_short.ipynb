{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team CoronaBoost\n",
    "477631,  \n",
    "Øyvind Samuelsen, Mikkel Nygard\n",
    "Challenge: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from category_encoders import TargetEncoder\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/test data\n",
    "train = pd.read_csv('data/challenge3_train.csv', index_col='id')\n",
    "test = pd.read_csv('data/challenge3_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper lists for column types\n",
    "features_bin = ['f0', 'f26'] # binary\n",
    "features_nom_low = ['f5'] # nominal low cardinality (<=3)\n",
    "features_nom_high = ['f12', 'f28'] # >= 26\n",
    "features_ord_low = ['f1', 'f2', 'f3', 'f6', 'f9', 'f11', 'f13', 'f15', 'f17', 'f18', 'f19', 'f20', 'f21', 'f23', 'f24', 'f25', 'f27', 'f29']\n",
    "features_ord_num = ['f1', 'f2', 'f3', 'f6', 'f9', 'f11', 'f13', 'f17', 'f18', 'f19', 'f21', 'f23', 'f24', 'f25', 'f27', 'f29']\n",
    "features_ord_high = ['f4', 'f10', 'f14']\n",
    "features_real = ['f7', 'f8', 'f16', 'f22', 'f30'] # real numbers.\n",
    "\n",
    "features_ord_alph = ['f15', 'f20']\n",
    "ohe_columns = features_ord_alph + features_nom_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "Based on exploration we have done these steps for data cleaning. After each step we tested to see if the accuracy in a basic XGB model improved, to decide if we would include it or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 0 value noise, change to most common value in column. \n",
    "impute_0_columns = ['f3', 'f18', 'f21']\n",
    "\n",
    "for column in impute_0_columns:\n",
    "    train.loc[train[column] == 0, column] = train[column].mode() # mode() finds most common value\n",
    "    test.loc[test[column] == 0, column] = test[column].mode()\n",
    "\n",
    "# remove -1 from 'month' column f11\n",
    "train.loc[train['f11'] == -1, 'f11'] = train['f11'].mode()\n",
    "test.loc[test['f11'] == -1, 'f11'] = test['f11'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Similar to data cleaning, we have tested each step to see if it improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improves\n",
    "train['f6_f0'] = train['f6'].fillna(1)**2*train['f0'].fillna(1)**2\n",
    "test['f6_f0'] = test['f6'].fillna(1)**2*test['f0'].fillna(1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improves\n",
    "train['f6_f25'] = train['f6'].fillna(1)**2*train['f25'].fillna(1)**2\n",
    "test['f6_f25'] = test['f6'].fillna(1)**2*test['f25'].fillna(1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hypothesise column f11 describes months, from 0-11\n",
    "# so add cyclical feature\n",
    "def cyc_enc(df, col, max_vals):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n",
    "    return df\n",
    "train = cyc_enc(train, 'f11', 11)\n",
    "test = cyc_enc(test, 'f11', 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For columns with dtype 'object' we need to represent them as numeric.\n",
    "# One hot encoding gave us best result, compared to label encoding and target encoding.\n",
    "train = pd.get_dummies(train, columns=ohe_columns + features_nom_high)\n",
    "test = pd.get_dummies(test, columns=ohe_columns + features_nom_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "We use XGBoost, CatBoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into a train and test set\n",
    "X = train.drop(['target'], axis=1)\n",
    "y = train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9139207358865746\n",
      "CPU times: user 2min 40s, sys: 954 ms, total: 2min 41s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgbmodel = XGBRegressor(**{'colsample_bytree': 0.7048862950970731,\n",
    " 'gamma': 0.6870786593228237,\n",
    " 'learning_rate': 0.043037814961976235,\n",
    " 'max_depth': 8,\n",
    " 'reg_alpha': 0.12849120484354531,\n",
    " 'reg_lambda': 0.21891264474184496,\n",
    "})\n",
    "\n",
    "xgbmodel.fit(X_train, y_train, verbose=False)\n",
    "predictions = xgbmodel.predict(X_test)\n",
    "#calculate score\n",
    "base_score = roc_auc_score(y_test, predictions)\n",
    "print(base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import make_scorer\n",
    "from hyperopt import fmin, hp, tpe\n",
    "import gc\n",
    "import time\n",
    "\n",
    "RANDOM_STATE = 42 # \n",
    "\n",
    "# Use Hyperopt to optimize xgboost parameters.\n",
    "def objective(params):\n",
    "    time1 = time.time()\n",
    "\n",
    "    print(\"\\n############## New Run ################\")\n",
    "    print(f\"params = {params}\")\n",
    "    FOLDS = 5\n",
    "    count=1\n",
    "    kf = KFold(n_splits=FOLDS, shuffle=True) # random_state=params['random_state']\n",
    "\n",
    "    y_preds = np.zeros(test.shape[0])\n",
    "    score_mean = 0\n",
    "    scal_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "    for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        clf = XGBRegressor(\n",
    "            n_estimators=300, \n",
    "            scale_pos_weight=scal_pos_weight,\n",
    "            **params\n",
    "        )\n",
    "        clf.fit(X_tr, y_tr),\n",
    "\n",
    "        predictions = clf.predict(X_val)\n",
    "        #calculate score\n",
    "        score = roc_auc_score(y_val, predictions)\n",
    "        score_mean += score\n",
    "        print(f'{count} CV - score: {round(score, 4)}')\n",
    "        count += 1\n",
    "    time2 = time.time() - time1\n",
    "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
    "    gc.collect()\n",
    "    print(f'Mean ROC_AUC: {score_mean / FOLDS}')\n",
    "    del X_tr, X_val, y_tr, y_val, clf, score\n",
    "    \n",
    "    return -(score_mean / FOLDS)\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "space = {\n",
    "    #'random_state': RANDOM_STATE,\n",
    "    \n",
    "    # The maximum depth of a tree, same as GBM.\n",
    "    # Used to control over-fitting as higher depth will allow model \n",
    "    # to learn relations very specific to a particular sample.\n",
    "    # Should be tuned using CV.\n",
    "    # Typical values: 3-10\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 10, dtype=int)),\n",
    "    \n",
    "    # reg_alpha: L1 regularization term. L1 regularization encourages sparsity \n",
    "    # (meaning pulling weights to 0). It can be more useful when the objective\n",
    "    # is logistic regression since you might need help with feature selection.\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    \n",
    "    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n",
    "    # approach can be more useful in tree-models where zeroing \n",
    "    # features might not make much sense.\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    \n",
    "    # eta: Analogous to learning rate in GBM\n",
    "    # Makes the model more robust by shrinking the weights on each step\n",
    "    # Typical final values to be used: 0.01-0.2\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.15),\n",
    "    \n",
    "    # colsample_bytree: Similar to max_features in GBM. Denotes the \n",
    "    # fraction of columns to be randomly samples for each tree.\n",
    "    # Typical values: 0.5-1\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    \n",
    "    # A node is split only when the resulting split gives a positive\n",
    "    # reduction in the loss function. Gamma specifies the \n",
    "    # minimum loss reduction required to make a split.\n",
    "    # Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    \n",
    "    # subsample: represents a fraction of the rows (observations) to be \n",
    "    # considered when building each subtree. Tianqi Chen and Carlos Guestrin\n",
    "    # in their paper A Scalable Tree Boosting System recommend \n",
    "    'subsample': hp.choice('subsample', [.5, 0.6, 0.7, .8]),\n",
    "    \n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 5, 1),\n",
    "    \n",
    "    'eval_metric': 'auc',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# We use hyperpot to find the best hyperparameters\n",
    "# Note: takes forever\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,\n",
    "           )\n",
    "\"\"\"\n",
    "**{'colsample_bytree': 0.7048862950970731,\n",
    " 'gamma': 0.6870786593228237,\n",
    " 'learning_rate': 0.043037814961976235,\n",
    " 'max_depth': 8,\n",
    " 'reg_alpha': 0.12849120484354531,\n",
    " 'reg_lambda': 0.21891264474184496,\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_roc_curve(test_y, predictions):\n",
    "    fpr, tpr, _ = roc_curve(test_y, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #xgb.plot_importance(gbm)\n",
    "    #plt.show()\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "print_roc_curve(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9108178905257609\n",
      "CPU times: user 3min 46s, sys: 942 ms, total: 3min 47s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# now lets try tuning xgboost by letting it stop learning when the validation score stops improving, \n",
    "# and letting it cycle through the learning process until it does so\n",
    "\n",
    "my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "\n",
    "# fit new df to model\n",
    "my_model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)], verbose=False)\n",
    "# generate predictions\n",
    "predictions = my_model.predict(X_test)\n",
    "#calculate score\n",
    "tuned_score = roc_auc_score(y_test, predictions)\n",
    "print(tuned_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training final model, predict test set and delivery csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f28_wa</th>\n",
       "      <th>f28_xB</th>\n",
       "      <th>f28_xF</th>\n",
       "      <th>f28_xG</th>\n",
       "      <th>f28_yE</th>\n",
       "      <th>f28_yK</th>\n",
       "      <th>f28_zc</th>\n",
       "      <th>f28_ze</th>\n",
       "      <th>f28_zf</th>\n",
       "      <th>f28_zp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.5573</td>\n",
       "      <td>14.3455</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.5487</td>\n",
       "      <td>14.3633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.9250</td>\n",
       "      <td>14.3287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.8335</td>\n",
       "      <td>13.9793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>99995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.8409</td>\n",
       "      <td>14.3688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>99996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.4951</td>\n",
       "      <td>14.4914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>99997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0421</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>99998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.1088</td>\n",
       "      <td>14.3610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>99999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.4363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   f0   f1   f2   f3      f4   f6       f7       f8   f9  ...  \\\n",
       "0      50000  NaN  5.0  5.0  3.0  3220.0  4.0 -11.5573  14.3455  4.0  ...   \n",
       "1      50001  NaN  4.0  4.0  3.0     NaN  3.0  -4.5487  14.3633  0.0  ...   \n",
       "2      50002  0.0  NaN  NaN  4.0  1916.0  2.0      NaN  14.1969  1.0  ...   \n",
       "3      50003  NaN  2.0  2.0  1.0   334.0  NaN  -4.9250  14.3287  0.0  ...   \n",
       "4      50004  NaN  4.0  4.0  3.0   828.0  4.0 -11.8335  13.9793  0.0  ...   \n",
       "...      ...  ...  ...  ...  ...     ...  ...      ...      ...  ...  ...   \n",
       "49995  99995  NaN  NaN  2.0  5.0   544.0  5.0  -6.8409  14.3688  0.0  ...   \n",
       "49996  99996  NaN  NaN  0.0  1.0     NaN  3.0  -5.4951  14.4914  3.0  ...   \n",
       "49997  99997  0.0  3.0  4.0  4.0  1182.0  3.0      NaN  14.0421  3.0  ...   \n",
       "49998  99998  NaN  3.0  5.0  5.0  2551.0  NaN -10.1088  14.3610  NaN  ...   \n",
       "49999  99999  NaN  5.0  0.0  1.0  3081.0  NaN      NaN  14.4363  0.0  ...   \n",
       "\n",
       "       f28_wa  f28_xB  f28_xF  f28_xG  f28_yE  f28_yK  f28_zc  f28_ze  f28_zf  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "49995       0       0       0       0       0       0       0       0       0   \n",
       "49996       0       0       0       0       0       0       0       0       0   \n",
       "49997       0       0       0       0       0       0       0       0       0   \n",
       "49998       0       0       0       0       0       0       0       0       0   \n",
       "49999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       f28_zp  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "49995       0  \n",
       "49996       0  \n",
       "49997       0  \n",
       "49998       0  \n",
       "49999       0  \n",
       "\n",
       "[50000 rows x 473 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgbmodel = XGBRegressor(**{'colsample_bytree': 0.7048862950970731,\n",
    " 'gamma': 0.6870786593228237,\n",
    " 'learning_rate': 0.043037814961976235,\n",
    " 'max_depth': 8,\n",
    " 'reg_alpha': 0.12849120484354531,\n",
    " 'reg_lambda': 0.21891264474184496,\n",
    "})\n",
    "\n",
    "xgbmodel.fit(X, y, verbose=False)\n",
    "predictions = xgbmodel.predict(test)\n",
    "#calculate score\n",
    "base_score = roc_auc_score(y_test, predictions)\n",
    "print(base_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
