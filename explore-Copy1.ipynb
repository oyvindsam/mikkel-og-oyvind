{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (50000, 33) | test: (50000, 32), all: (100000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3598.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.2430</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.834041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.6662</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.686021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target   f0   f1   f2   f3      f4   f5   f6      f7  ...  f21  \\\n",
       "0   0       1  0.0  5.0  0.0  4.0  3598.0    M  3.0 -7.2430  ...  3.0   \n",
       "1   1       0  NaN  5.0  4.0  NaN  2072.0  NaN  4.0 -1.6662  ...  3.0   \n",
       "\n",
       "       f22  f23  f24  f25  f26  f27 f28  f29       f30  \n",
       "0  14.2364  0.0  NaN  4.0  1.0  5.0  PS  2.0  0.834041  \n",
       "1      NaN  2.0  3.0  NaN  1.0  5.0  DT  5.0  0.686021  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/challenge3_train.csv')\n",
    "test = pd.read_csv('data/challenge3_test.csv')\n",
    "data = pd.concat([train, test])\n",
    "print(f'train: {train.shape} | test: {test.shape}, all: {data.shape}')\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce5cfb7286f4e7c9bff234b17ac172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=48.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97ad2088221486894b5853a67583ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a92874a424446498d0c11008d559c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render HTML', max=1.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2ff7c3971e4065b593310f888648f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Export report to file', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3d8f00781c42088800b04310e2ee61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=48.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d16a53b021541b0a3c17ffbeea125c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48b1bf653764eaa97f3ea2570cb5441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render HTML', max=1.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ccb7afac95455dbb00995641e587a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Export report to file', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate reports\n",
    "#pandas_profiling.ProfileReport(train, minimal=False).to_file('train_report.html')\n",
    "#pandas_profiling.ProfileReport(test, minimal=False).to_file('test_report_small.html')\n",
    "\n",
    "# Report for 1/0 class\n",
    "#pandas_profiling.ProfileReport(train[train['target'] == 1], minimal=False).to_file('train_1_report.html')\n",
    "#pandas_profiling.ProfileReport(train[train['target'] == 0], minimal=False).to_file('train_0_report.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing train and test data: \n",
    "From reports we see f13 has different data distribution; more outliers around 28 and 60.\n",
    "\n",
    "\n",
    "High corelevance with f10 and f14\n",
    "\n",
    "Categorical:\n",
    "f5: M, F\n",
    "f15: A, B, C\n",
    "f20: A-Z\n",
    "\n",
    "## Compare 1/0 target class\n",
    "#### 1 target:\n",
    "- correlations (which are not present in other target): \n",
    "    - f21-f6 (very high). f21: 1-5, uniform distributiuon (target 0 is more normal-like). f6: 0-5, bit skewed to the right uniform dist. \n",
    "    - f25-f6 f25: uniform-ish except 0. \n",
    "    - f26-f4. f26: boolean, many 1. f4: real, lower mean, std\n",
    "#### 0 target:\n",
    "- correlations:\n",
    "    - f26-f0. f26: bool, more are false than target 1. f0: bool\n",
    "    - f26-f6. f6: 0-5, 4 most common, higher mean than t1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: factorize f15, A and C can probably be switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of values being NaN')\n",
    "nans = data.isna().sum().map(lambda x: x / len(data) * 100).round(1)\n",
    "pd.DataFrame({'Nan percentage': nans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_vals = list()\n",
    "\n",
    "for column in data:\n",
    "    nunique_vals.append(data[column].nunique())\n",
    "print('Unique values in columns:')\n",
    "pd.DataFrame({'columns': data.columns,\n",
    "              'unique_values': nunique_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    unique = data[column].unique()\n",
    "    count = len(unique)\n",
    "    print('Column', column)\n",
    "    print('Values:', unique)\n",
    "    print('Number of unique:', count)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of unique values and Nan:')      \n",
    "for column in data.columns:\n",
    "    count = len(data[column].unique())\n",
    "    if count > 30:\n",
    "        continue # Too many values to compute/display graph on\n",
    "    value_percent = data[column].value_counts(dropna=False, sort=False).map(lambda x: x / len(data[column]) * 100).sort_index()\n",
    "    print('Column', column)\n",
    "    print(value_percent)\n",
    "    \n",
    "    ax = value_percent.plot.bar(rot=0)\n",
    "    ax.set_title(column)\n",
    "    plt.ylabel('Percent')\n",
    "    plt.xlabel('Values')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the graphs we see the following\n",
    "Graphs with zero (0) as noise, meaning we can probably drop them:\n",
    "f1, f3, f18, f21, f24, f29\n",
    "\n",
    "f11 have noise in -1, in addition to 0.\n",
    "\n",
    "f17, f19 have only 0.002% and 0.001% 2 value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_columns = ['f1', 'f3', 'f11', 'f18', 'f21', 'f24', 'f29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Look into zero values in train and test set')\n",
    "for column in zero_columns:\n",
    "    print('\\n', column)\n",
    "    print('Zero value in feature grouped by target:')\n",
    "    print(train.loc[train[column] == 0].groupby([column, 'target']).size())\n",
    "    print('\\n')\n",
    "    print('Zero value count in train vs test set')\n",
    "    print('train:', train.loc[train[column] == 0].shape[0])\n",
    "    print('test :', test.loc[test[column] == 0].shape[0])\n",
    "    \n",
    "    if (column == 'f11'):\n",
    "        print('\\n')\n",
    "        print(train.loc[train[column] == -1].groupby([column, 'target']).size())\n",
    "        print('train:', train.loc[train['f11'] == -1].shape[0])\n",
    "        print('test :', test.loc[test['f11'] == -1].shape[0])\n",
    "\n",
    "print('We see 0 value can be removed/changed safely from f3, f18, f21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now explore train data (with known target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tageet distribution:')\n",
    "train['target'].value_counts().plot.bar()\n",
    "plt.show()\n",
    "print('We see targets are not balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['f5', 'target'])\n",
    "percent = group.size().groupby(level=0).apply(lambda count: count / len(count) * 100).rename('Percent').reset_index()\n",
    "pivot = percent.pivot('target', 'f5', 'Percent')\n",
    "\n",
    "ax = pivot.plot.bar(stacked=False, rot=0)\n",
    "plt.title('f5 (Gender) target distribution')\n",
    "plt.ylabel('Percent')\n",
    "plt.xlabel('Target')\n",
    "plt.show()\n",
    "print('We see that F and M have very similar target distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['f15', 'target'])\n",
    "percent = group.size().groupby(level=0).apply(lambda count: 100 * count / count.sum()).rename('Percent').reset_index()\n",
    "pivot = percent.pivot('target', 'f15', 'Percent')\n",
    "\n",
    "ax = pivot.plot.bar(stacked=False, rot=0)\n",
    "plt.title('f15 (A, B, C) target distribution')\n",
    "plt.ylabel('Percent')\n",
    "plt.xlabel('Target')\n",
    "plt.show()\n",
    "print('We see that A, B, C have very different target distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['f20', 'target'])\n",
    "percent = group.size().groupby(level=0).apply(lambda count: 100 * count / count.sum()).rename('Percent').reset_index()\n",
    "pivot = percent.pivot('target', 'f20', 'Percent')\n",
    "\n",
    "ax = pivot.plot.bar(stacked=False, rot=0)\n",
    "plt.title('f20 target distribution')\n",
    "plt.ylabel('Percent')\n",
    "plt.xlabel('Target')\n",
    "plt.show()\n",
    "print('We see that the labels have very simmilar target distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are some differences in training and test data')\n",
    "train['f13'].plot.hist(bins=100)\n",
    "test['f13'].plot.hist(bins=100, alpha=.5)\n",
    "\n",
    "plt.show()\n",
    "print('Here we see the frequency of some values in the training data are higher than in test')\n",
    "print('Since f13 are whole numbers, most are between 28-29, and 62-63')\n",
    "pd.DataFrame({'frequency count': train['f13'].value_counts(bins=100).head(60).head(2)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['f5'] == 'F']['f13'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['f5'] == 'M']['f13'].plot.hist(bins=len(pd.unique(train['f13'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['f5'] == 'M') & (train['f13'] == 44), 'f13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['f5'] == 'M']['f13'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = group.size().groupby(level=0).apply(lambda count: 100 * count / count.sum()).rename('Percent').reset_index()\n",
    "pivot = percent.pivot('target', 'f', 'Percent')\n",
    "\n",
    "ax = pivot.plot.bar(stacked=False, rot=0)\n",
    "plt.title('f20 target distribution')\n",
    "plt.ylabel('Percent')\n",
    "plt.xlabel('Target')\n",
    "plt.show()\n",
    "print('We see that the labels have very simmilar target distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of curiosity we want to explore the rows with a 1 and a 0 separately\n",
    "true_train = train.loc[train['target'] == 1]\n",
    "false_train = train.loc[train['target'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_profile = pandas_profiling.ProfileReport(true_train_data, minimal=True).to_file('true_train_report.html')\n",
    "true_profile = pandas_profiling.ProfileReport(false_train_data, minimal=True).to_file('false_train_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the different in distribution of values within each column with respect to whether the target is a 0 or a 1\n",
    "the interesting columns seem to be:\n",
    "f0, f1, f2, f3, f4, f6, f13, f14(?) f15, f17, f18, f19, f21, f23, f24, f25, f26\n",
    "\n",
    "f13: different distribution, and 0 class have a weird common interval. Feature could be age, since values are whole numbers. \n",
    "then negative values are noise, and should be removed. \n",
    "\n",
    "f15: (A, B, C column) is _very_ discriminating between 0 and 1. A is twice as often a 1 than C, and the opposite for 0. \n",
    " B have equal distribution.\n",
    " \n",
    "f18: Many '5' values are class 1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
